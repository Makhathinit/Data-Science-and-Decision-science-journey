{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dc30a5-f635-4a3f-98ad-12327138d96b",
   "metadata": {},
   "source": [
    "## What are the key features of Apache Spark\n",
    "1. Unified Analytics Engine: Spark provides a unified platform for various data processing tasks, including batch processing, streaming, interactive queries, and machine learning.\n",
    "\n",
    "2.Speed: Spark achieves high performance through in-memory processing and optimized execution.\n",
    "\n",
    "3.Ease of Use: Spark offers user-friendly APIs in multiple languages, including Python, Java, Scala, and R.\n",
    "\n",
    "4.Versatility: Spark can process data from various sources, including Hadoop Distributed File System (HDFS), cloud storage (e.g., Amazon S3), and databases.\n",
    "\n",
    "5.Fault Tolerance: Spark's Resilient Distributed Datasets (RDDs) and DataFrame abstractions provide fault tolerance by automatically recovering from failures.\n",
    "\n",
    "6.Scalability: Spark can scale from small datasets on a single machine to large datasets on a cluster of thousands of machines.\n",
    "\n",
    "7.Rich Ecosystem: Spark has a rich ecosystem of libraries, including:\n",
    "\n",
    "Spark SQL: For structured data processing.\n",
    "\n",
    "Spark Streaming: For real-time data processing.\n",
    "\n",
    "MLlib: For machine learning.\n",
    "\n",
    "GraphX: For graph processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31a79a-0828-409d-ad77-0a185fe8a089",
   "metadata": {},
   "source": [
    "### Explain Sparkâ€™s architecture\n",
    "\n",
    "Apache Spark Architecture: Spark's architecture is designed to be fast and flexible. It has a layered architecture with several key components:\n",
    "\n",
    "1.Driver Node: The driver is the main process that controls the application. It's responsible for:\n",
    "Maintaining the state of the application.\n",
    "Creating the SparkContext.\n",
    "Distributing the application code to the executors.\n",
    "Submitting tasks to the executors.\n",
    "\n",
    "2.Cluster Manager: Spark relies on a cluster manager to allocate resources across the worker nodes. Spark supports various cluster managers, including:\n",
    "\n",
    "Spark's Standalone Cluster Manager: A simple cluster manager that comes with Spark.\n",
    "Hadoop YARN: The resource management layer in Hadoop.\n",
    "Apache Mesos: A cluster manager that can run various frameworks.\n",
    "Kubernetes: A container orchestration platform.\n",
    "\n",
    "3.Worker Nodes: Worker nodes are the machines in the cluster that run the actual tasks. Each worker node has one or more executors.\n",
    "\n",
    "4.Executors: Executors are processes that run on worker nodes and are responsible for:\n",
    "\n",
    "Executing the tasks assigned to them by the driver.\n",
    "Storing data in memory (cache).\n",
    "Returning results to the driver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1c6fbf-6c2f-4a0d-989f-ac5027c0039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c75bef-f070-4b32-81ed-6231e11215c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ed5d48-2c2b-4e2c-8391-13dcd5c5660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 11:08:50 WARN Utils: Your hostname, Thabisos-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.5.5.170 instead (on interface en0)\n",
      "25/04/22 11:08:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/22 11:08:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/22 11:08:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark_Assessment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f85dde8-8d02-481c-ad2d-29d57649ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext \n",
    "sc = SparkContext.getOrCreate()\n",
    "even_num = [2,4,6,8,10,12]\n",
    "rdd = sc.parallelize(even_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d7352e-f337-43ce-b9f3-f909e4be338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, struct\n",
    "(\"Peter\", 40, {\"id\": 3, \"name\": \"Agent Brown\", \"office\": \"HQ\", \"code\": 9012})\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22117e9c-57e7-45a0-91ee-bf0a430a340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [({\"id\": 1},\"John Doe\",\"Engineering\",75000), \n",
    "         ({\"id\": 2},\"Jane Smith\",\"Marketing\",60000),\n",
    "         ({\"id\": 3},\"Bob Johnson\",\"Engineering\",80000),\n",
    "         ({\"id\": 4},\"Alice Williams\",\"Sales\",50000),\n",
    "         ({\"id\": 5},\"Tom Brown\",\"Marketing\",65000)]\n",
    "columns = [\"agent_id\",\"name\",\"department\",\"salary\"]\n",
    "\n",
    " # Create a DataFrame\n",
    "agents_data = spark.createDataFrame(data, schema=columns)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c68fe1d-4ad8-4b30-8888-c9947c73ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+------+\n",
      "| agent_id|          name| department|salary|\n",
      "+---------+--------------+-----------+------+\n",
      "|{id -> 1}|      John Doe|Engineering| 75000|\n",
      "|{id -> 2}|    Jane Smith|  Marketing| 60000|\n",
      "|{id -> 3}|   Bob Johnson|Engineering| 80000|\n",
      "|{id -> 4}|Alice Williams|      Sales| 50000|\n",
      "|{id -> 5}|     Tom Brown|  Marketing| 65000|\n",
      "+---------+--------------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show CSV file \n",
    "agents_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "287e343f-e5f1-4bd8-9b60-23fc06360680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=============================>                            (4 + 4) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "| department|avg_salary|\n",
      "+-----------+----------+\n",
      "|Engineering|   77500.0|\n",
      "|  Marketing|   62500.0|\n",
      "|      Sales|   50000.0|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Calculate the average salary for each department and filter\n",
    "from pyspark.sql.functions import col, avg\n",
    "dept_avg_salary = agents_data.groupBy(\"department\").agg(avg(col(\"salary\")).alias(\"avg_salary\"))\n",
    "dept_avg_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3055cfbd-39ca-40e7-bb9f-8335faab2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "dept_avg_salary.write.csv(\"/Users/thabisomakhathini/Downloads/dept_avg_salary.csv\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49d6f3e0-c800-4945-8ae4-3fd9e397248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+--------+----------+----------+-----------+----------+--------------+---------+---------+--------+---------+----------+----------+--------------+----------+----------+---------+------+----------------+----------+-------+-------+----------+-----+\n",
      "|car_ID|symboling|             CarName|fueltype|aspiration|doornumber|    carbody|drivewheel|enginelocation|wheelbase|carlength|carwidth|carheight|curbweight|enginetype|cylindernumber|enginesize|fuelsystem|boreratio|stroke|compressionratio|horsepower|peakrpm|citympg|highwaympg|price|\n",
      "+------+---------+--------------------+--------+----------+----------+-----------+----------+--------------+---------+---------+--------+---------+----------+----------+--------------+----------+----------+---------+------+----------------+----------+-------+-------+----------+-----+\n",
      "|     1|        3|  alfa-romero giulia|     gas|       std|       two|convertible|       rwd|         front|     88.6|    168.8|    64.1|     48.8|      2548|      dohc|          four|       130|      mpfi|     3.47|  2.68|               9|       111|   5000|     21|        27|13495|\n",
      "|     2|        3| alfa-romero stelvio|     gas|       std|       two|convertible|       rwd|         front|     88.6|    168.8|    64.1|     48.8|      2548|      dohc|          four|       130|      mpfi|     3.47|  2.68|               9|       111|   5000|     21|        27|16500|\n",
      "|     3|        1|alfa-romero Quadr...|     gas|       std|       two|  hatchback|       rwd|         front|     94.5|    171.2|    65.5|     52.4|      2823|      ohcv|           six|       152|      mpfi|     2.68|  3.47|               9|       154|   5000|     19|        26|16500|\n",
      "|     4|        2|         audi 100 ls|     gas|       std|      four|      sedan|       fwd|         front|     99.8|    176.6|    66.2|     54.3|      2337|       ohc|          four|       109|      mpfi|     3.19|   3.4|              10|       102|   5500|     24|        30|13950|\n",
      "|     5|        2|          audi 100ls|     gas|       std|      four|      sedan|       4wd|         front|     99.4|    176.6|    66.4|     54.3|      2824|       ohc|          five|       136|      mpfi|     3.19|   3.4|               8|       115|   5500|     18|        22|17450|\n",
      "+------+---------+--------------------+--------+----------+----------+-----------+----------+--------------+---------+---------+--------+---------+----------+----------+--------------+----------+----------+---------+------+----------------+----------+-------+-------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/thabisomakhathini/Downloads/cars (3).csv\"\n",
    "cars = spark.read.csv(path,schema=None, sep=',', quote='\"', escape='\\\\', header=True,\n",
    "               inferSchema=False, nullValue=None, encoding=None, comment=None,\n",
    "               mode='PERMISSIVE')\n",
    "cars.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd88259a-574f-47fa-91dd-5c187b80740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17671bf8-aa8d-4097-a031-c697a00533f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_price_filter = cars.filter(col(\"Price\")>11000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "686ae696-e69a-40f4-b685-60e62fb45be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|fueltype|average_price|\n",
      "+--------+-------------+\n",
      "|     gas|   12999.7982|\n",
      "|  diesel|     15838.15|\n",
      "+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "car_avg_value_by_fueltype = cars.groupBy(\"fueltype\").agg(avg(col(\"price\")).alias(\"average_price\"))\n",
    "car_avg_value_by_fueltype.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26547fae-1f28-42af-bb77-29bfe0afab88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
